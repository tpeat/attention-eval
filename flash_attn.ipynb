{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4432cabd-8c14-4b7f-9cd6-92c58e56f4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "from flash_attn import flash_attn_func\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2413b16a-f666-4b92-a326-f5361dbfa88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "dtype=torch.float16\n",
    "embed_dim = 4\n",
    "num_heads = 2\n",
    "seq_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959670d8-4276-4d64-ad26-ae27bd5bade5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006763935089111328"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# unpacked version of flash attn (q, k, v)\n",
    "q = torch.rand(1, 512, 30, 30, dtype=dtype).to(device)\n",
    "dp = 0.1\n",
    "\n",
    "s = time.time()\n",
    "out = flash_attn_func(q, q, q, dropout_p = dp)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c44fc2a-6e50-4dda-aff3-5d325d89e48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314464092254639"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, v = q, q\n",
    "\n",
    "s = time.time()\n",
    "# similarity\n",
    "sim = q @ k\n",
    "\n",
    "# attention\n",
    "attn = sim.softmax(dim=-1)\n",
    "\n",
    "# aggregate values\n",
    "out = attn @ v\n",
    "\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be1457c5-5e08-4309-b9d3-62526dce63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_ychunks(x, y, chunks=1):\n",
    "    if chunks <= 1:\n",
    "        return x @ y\n",
    "    else:\n",
    "        return torch.cat([x @ _y for _y in y.chunk(chunks, dim=-1)], dim=-1)\n",
    "\n",
    "\n",
    "def multiply_by_xchunks(x, y, chunks=1):\n",
    "    if chunks <= 1:\n",
    "        return x @ y\n",
    "    else:\n",
    "        return torch.cat([_x @ y for _x in x.chunk(chunks, dim=-2)], dim=-2)\n",
    "    \n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 num_head=8,\n",
    "                 dropout=0.,\n",
    "                 use_linear=True,\n",
    "                 d_att=None,\n",
    "                 use_dis=False,\n",
    "                 qk_chunks=1,\n",
    "                 max_mem_len_ratio=-1,\n",
    "                 top_k=-1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.use_dis = use_dis\n",
    "        self.qk_chunks = qk_chunks\n",
    "        self.max_mem_len_ratio = float(max_mem_len_ratio)\n",
    "        self.top_k = top_k\n",
    "\n",
    "        self.hidden_dim = d_model // num_head\n",
    "        self.d_att = self.hidden_dim if d_att is None else d_att\n",
    "        self.T = self.d_att**0.5\n",
    "        self.use_linear = use_linear\n",
    "\n",
    "        if use_linear:\n",
    "            self.linear_Q = nn.Linear(d_model, d_model)\n",
    "            self.linear_K = nn.Linear(d_model, d_model)\n",
    "            self.linear_V = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.drop_prob = dropout\n",
    "        self.projection = nn.Linear(d_model, d_model)\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        \"\"\"\n",
    "        :param Q: A 3d tensor with shape of [T_q, bs, C_q]\n",
    "        :param K: A 3d tensor with shape of [T_k, bs, C_k]\n",
    "        :param V: A 3d tensor with shape of [T_v, bs, C_v]\n",
    "        \"\"\"\n",
    "        # print(\"MultiheadAttention:\", Q.shape, K.shape, V.shape)\n",
    "        num_head = self.num_head\n",
    "        hidden_dim = self.hidden_dim\n",
    "\n",
    "        bs = Q.size()[1]\n",
    "\n",
    "        # Linear projections\n",
    "        if self.use_linear:\n",
    "            Q = self.linear_Q(Q)\n",
    "            K = self.linear_K(K)\n",
    "            V = self.linear_V(V)\n",
    "\n",
    "        # Scale\n",
    "        Q = Q / self.T\n",
    "\n",
    "        if not self.training and self.max_mem_len_ratio > 0:\n",
    "            mem_len_ratio = float(K.size(0)) / Q.size(0)\n",
    "            if mem_len_ratio > self.max_mem_len_ratio:\n",
    "                scaling_ratio = math.log(mem_len_ratio) / math.log(\n",
    "                    self.max_mem_len_ratio)\n",
    "                Q = Q * scaling_ratio\n",
    "\n",
    "        # Multi-head\n",
    "        Q = Q.view(-1, bs, num_head, self.d_att).permute(1, 2, 0, 3)\n",
    "        K = K.view(-1, bs, num_head, self.d_att).permute(1, 2, 3, 0)\n",
    "        V = V.view(-1, bs, num_head, hidden_dim).permute(1, 2, 0, 3)\n",
    "        # print(Q.shape, K.shape, V.shape)\n",
    "\n",
    "        # Multiplication\n",
    "        QK = multiply_by_ychunks(Q, K, self.qk_chunks)\n",
    "        if self.use_dis:\n",
    "            QK = 2 * QK - K.pow(2).sum(dim=-2, keepdim=True)\n",
    "\n",
    "        # Activation\n",
    "        if not self.training and self.top_k > 0 and self.top_k < QK.size()[-1]:\n",
    "            top_QK, indices = torch.topk(QK, k=self.top_k, dim=-1)\n",
    "            top_attn = torch.softmax(top_QK, dim=-1)\n",
    "            attn = torch.zeros_like(QK).scatter_(-1, indices, top_attn)\n",
    "        else:\n",
    "            attn = torch.softmax(QK, dim=-1)\n",
    "\n",
    "        # Dropouts\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # Weighted sum\n",
    "        outputs = multiply_by_xchunks(attn, V,\n",
    "                                      self.qk_chunks).permute(2, 0, 1, 3)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = outputs.reshape(-1, bs, self.d_model)\n",
    "        outputs = self.projection(outputs)\n",
    "        # print(outputs.shape)\n",
    "        return outputs, attn\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edad5bd-06b7-456a-bd7e-9c622fdadd0c",
   "metadata": {},
   "source": [
    "## Verify the same output for Mulithead and flash\n",
    "\n",
    "Note: we don't expect any speedup in this low dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0e3ae57-383b-4f51-97e5-07e4991c79fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn2 = MultiheadAttention(embed_dim, num_head = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26119599-f3f2-4379-a977-46529e4dfdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.rand(seq_len, 1, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a19724ff-880d-4f60-a3ac-211a1697af58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4, 2]) torch.Size([1, 2, 2, 4]) torch.Size([1, 2, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0006425380706787109"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "out, out_drop = attn2(x, x, x)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "466d9b14-4d53-442a-859f-8ac81362dbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1673,  0.1168, -0.6121, -0.8281]],\n",
       "\n",
       "        [[-0.1641,  0.1154, -0.6128, -0.8274]],\n",
       "\n",
       "        [[-0.1716,  0.1183, -0.6124, -0.8301]],\n",
       "\n",
       "        [[-0.1704,  0.1181, -0.6121, -0.8295]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ac35fb1-dd81-4f75-b2dc-722f2f656f83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 36, 8, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use flash attention in the same manner as Multihead\n",
    "# 1 reshape current tensor to match: bs, seq len, nheads, headdim\n",
    "d_att = embed_dim // num_heads\n",
    "bs = x.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978001c5-af20-460e-8fb7-cdcd4ca7d06d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008258819580078125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "d_att = embed_dim // num_heads\n",
    "bs = x.size()[1]\n",
    "y = x.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "out3 = flash_attn_func(y, y, y, dropout_p = dp)\n",
    "out3 = out3.reshape(-1, bs, embed_dim)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df475be5-eaf6-45fc-af6e-7f93d4627445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 1, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d871c1eb-b62f-46c1-beab-6e7db5545d62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1673,  0.1168, -0.6121, -0.8281]],\n",
       "\n",
       "        [[-0.1641,  0.1154, -0.6128, -0.8274]],\n",
       "\n",
       "        [[-0.1716,  0.1183, -0.6124, -0.8301]],\n",
       "\n",
       "        [[-0.1704,  0.1181, -0.6121, -0.8295]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f991ae7-07e4-4710-b5b2-82bd1eab323c",
   "metadata": {},
   "source": [
    "## Repeat experiment but in higher dim\n",
    "\n",
    "From earlier experiments wittnessed seq_len = 289 and embed_dim = 256\n",
    "\n",
    "Also have seen seq len 900, embed_dim 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e05aa87e-7518-4abb-b738-ac91ae5f3f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "seq_len = 900\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c4b88e5-a79b-47ef-b2fe-3fb07e5ae35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn4 = MultiheadAttention(embed_dim, num_head = num_heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f43863c8-3b12-4756-a71f-cf7849f780f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lq = torch.rand(seq_len, bs, embed_dim).to(device) # lq = larger q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57b572da-8a06-4d2e-9efd-9afc909ebc10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 900, 32]) torch.Size([4, 8, 32, 900]) torch.Size([4, 8, 900, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0014352798461914062"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "out4, out_drop = attn4(lq, lq, lq)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38dd85c3-ad1e-47d4-86d9-ca042fea63ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004987716674804688"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "d_att = embed_dim // num_heads\n",
    "bs = lq.size()[1]\n",
    "y = lq.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "out5 = flash_attn_func(y, y, y, dropout_p = dp)\n",
    "out5 = out5.reshape(-1, bs, embed_dim)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b6956-209e-42fa-a518-9045891a95c5",
   "metadata": {},
   "source": [
    "## Repeat calculation 10000 times and compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f87b632d-115b-444a-8d48-d8bc3eb9bfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3023f71b-b398-4570-a230-431a506f2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010495921850204467"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform the function call\n",
    "    out6, out_drop = attn4(lq, lq, lq)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "avg_runtime = total_time / num_iterations\n",
    "avg_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea7cabc-c5eb-45b6-9f06-758f5216ba47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.724754810333252e-05"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    d_att = embed_dim // num_heads\n",
    "    bs = lq.size()[1]\n",
    "    y = lq.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "    out7 = flash_attn_func(y, y, y, dropout_p = dp)\n",
    "    out7 = out7.reshape(-1, bs, embed_dim)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "avg_runtime = total_time / num_iterations\n",
    "avg_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c316b-1607-4336-939f-1d45d0c706f5",
   "metadata": {},
   "source": [
    " ## Increasing realism of experiments\n",
    "\n",
    "making it more realistic I'd have 3 seperate qkv for each (not sure how cuda caches computations, but might be artifiically speeding up)\n",
    "\n",
    "Note: turned off manual seed\n",
    "\n",
    "Notice that reshapping all 3 takes significantly more time, just barely faster than multiheadd attention now\n",
    "\n",
    "Mixed emotions about this, because most likely the tensor creation is the slow part, I'd like to run isolated experiments with full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55e83481-1848-4c2d-acbe-8b37de1044b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013247489929199219"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "rq = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "rk = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "rv = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "out8, out_drop = attn4(rq, rk, rv)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a52b6275-4de4-4c15-a151-270d163b9b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01303863525390625"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "rq = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "rk = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "rv = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "d_att = embed_dim // num_heads\n",
    "bs = rq.size()[1]\n",
    "q = rq.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "k = rk.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "v = rv.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "out9 = flash_attn_func(q, k, v, dropout_p = dp)\n",
    "out9 = out9.reshape(-1, bs, embed_dim)\n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4055c67d-cc49-4241-a123-a3137f16c1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012385438585281372"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## start func call\n",
    "    rq = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    rk = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    rv = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    out10, out_drop = attn4(rq, rk, rv)\n",
    "    # end func call\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "avg_runtime = total_time / num_iterations\n",
    "avg_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef39fabe-ba49-4435-a7bb-1aa87cbea086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012145824599266053"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    start_time = time.time()\n",
    "    ## start func call\n",
    "    \n",
    "    rq = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    rk = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    rv = torch.rand(seq_len, bs, embed_dim).to(device)\n",
    "    d_att = embed_dim // num_heads\n",
    "    bs = rq.size()[1]\n",
    "    q = rq.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "    k = rk.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "    v = rv.view(-1, bs, num_heads, d_att).permute(1, 0, 2, 3).to(dtype).to(device)\n",
    "    out11 = flash_attn_func(q, k, v, dropout_p = dp)\n",
    "    out11 = out11.reshape(-1, bs, embed_dim)\n",
    "    \n",
    "    ## end \n",
    "    end_time = time.time()\n",
    "    \n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "avg_runtime = total_time / num_iterations\n",
    "avg_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d41ab-ee2b-46cf-88ba-13f5d7a137f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11.6",
   "language": "python",
   "name": "cuda11.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
